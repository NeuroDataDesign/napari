{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Add swc\n",
    "This notebook demonstrates how to load neuron traces from [swc](http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html) files.\n",
    "\n",
    "To run napari from a jupyter notebook, you need to instantiate a `QT GUI`. You must wait for the `QT GUI` to instantiate before creating the `Viewer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt5\n",
    "# Note that this Magics command needs to be run in a cell\n",
    "# before any of the Napari objects are instantiated to\n",
    "# ensure it has time to finish executing before they are\n",
    "# called\n",
    "\n",
    "import napari\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading entire neuron\n",
    "To load the entire neuron from a swc, you need to specify the `swc_path`. By convention, vertex coordinates in the swc file are in micrometers (spatial units). Napari can read the swc file and convert the coordinates from spatial units to voxel units given the `spacing` (spatial units/voxel) and `origin` (spatial units).\n",
    "\n",
    "Conversion from spatial to voxel units is done with the following equation:\n",
    "\n",
    "$voxel = \\frac{spatial - origin}{spacing}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show neuron G-002\n",
    "# parameters\n",
    "consen_neuron_path = '2018-08-01_G-002_consensus.swc'\n",
    "spacing = np.array([0.29875923,0.3044159,0.98840415])\n",
    "origin = np.array([70093.276,15071.596,29306.737])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Shapes layer 'G-002' at 0x1480a7160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## show entire neuron G-002\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_swc(swc_path=consen_neuron_path, spacing=spacing, origin=origin, edge_color='white', name='G-002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot](G-002_consensus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot of entire neuron G-002 in napari. Neuron G-002 is from the [Mouselight](https://www.janelia.org/project-team/mouselight) data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading sub-neuron\n",
    "\n",
    "The image of the entire brain has dimensions of (33792, 25600, 13312) voxels. G-002 spans a sub-image of (7386, 9932, 5383) voxels. Both are too big to load in napari and overlay the neuron.\n",
    "To circumvent this, we can crop out a smaller region of the neuron, load the sub-neuron, and load the corresponding sub-image.\n",
    "\n",
    "In order to get a sub-neuron, we need to specify the `bounding_box` that will be used to crop the neuron. `bounding_box` is a length 2 tuple. The first element is one corner of the bounding box (inclusive) and the second element is the opposite corner of the bounding box (exclusive). Both corners are in voxel units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Shapes layer 'G-002_complex' at 0x14a38afd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## show sub-neuron from complex region of neuron G-002\n",
    "start = np.array([15312,4400,6448])  # start corner of the bounding_box\n",
    "end = np.array([15840,4800,6656])    # end corner of the bounding_box\n",
    "viewer_comp = napari.Viewer(ndisplay=3)\n",
    "viewer_comp.add_swc(swc_path=consen_neuron_path, spacing=spacing, origin=origin, bounding_box=(start,end), edge_color='blue', name='G-002_complex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now overlay the corresponding sub-image with the sub-neuron. This sub-image was already cropped from the image of the full brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image' at 0x14a124278>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = 'G-002_complex.tif'\n",
    "img_comp = io.imread(image_path)\n",
    "img_comp = np.swapaxes(img_comp,0,2) # this particular image is saved in (z,y,x) and so must have axes swapped to be (x,y,z)\n",
    "\n",
    "viewer_comp.add_image(img_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot](G-002_complex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot of the sub-neuron loaded into napari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari",
   "language": "python",
   "name": "napari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
